{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1f085c0",
   "metadata": {},
   "source": [
    "### feature ëŒ€ìƒìœ¼ë¡œ LGBM í•™ìŠµ  \n",
    "(Developed from dacon_etri_base_mod1.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0593c4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# í˜„ì¬ ë‚ ì§œ ë° ì‹œê°„ ê°€ì ¸ì˜¤ê¸°\n",
    "now = datetime.now()\n",
    "timestamp = now.strftime(\"%m%d_%H%M\")  # ì˜ˆ: 0517_1530\n",
    "\n",
    "\n",
    "submission_folder = '/users/KTL/Desktop/dacon/submission/'\n",
    "submission_file = f'submission_final_baseline_regular_{timestamp}.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bead988",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import glob \n",
    "import random \n",
    "import os \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import ast \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "import torch\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903c2113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed ê³ ì • \n",
    "SD = 42 \n",
    "random.seed(SD) \n",
    "np.random.seed(SD) \n",
    "os.environ['PYTHONHASHSEED'] = str(SD)\n",
    "tf.random.set_seed(SD)  # TensorFlow ì‹œë“œ ì„¤ì •\n",
    "\n",
    "# íŒŒì¼ ê²½ë¡œ ì„¤ì • - VSCode ìƒëŒ€ê²½ë¡œë¡œ ë³€ê²½\n",
    "# ì‹¤ì œ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì • í•„ìš”\n",
    "base_folder =  '/users/KTL/Desktop/ETRI_lifelog_dataset'\n",
    "folder = '/ch2025_data_items'\n",
    "\n",
    "data_dir = base_folder + folder \n",
    "\n",
    "\n",
    "# Parquet íŒŒì¼ ì „ì²´ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ \n",
    "parquet_files = glob.glob(os.path.join(data_dir, 'ch2025_*.parquet')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9028dc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŒŒì¼ ì´ë¦„ì„ í‚¤ë¡œ, DataFrameì„ ê°’ìœ¼ë¡œ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬ \n",
    "lifelog_data = {} \n",
    "\n",
    "# íŒŒì¼ë³„ë¡œ ì½ê¸° \n",
    "for file_path in parquet_files: \n",
    "    name = os.path.basename(file_path).replace('.parquet', '').replace('ch2025_', '') \n",
    "    lifelog_data[name] = pd.read_parquet(file_path) \n",
    "    print(f\"âœ… Loaded: {name}, shape = {lifelog_data[name].shape}\") \n",
    "\n",
    "# ë”•ì…”ë„ˆë¦¬ì— ìˆëŠ” ëª¨ë“  í•­ëª©ì„ ë…ë¦½ì ì¸ ë³€ìˆ˜ë¡œ í• ë‹¹ \n",
    "for key, df in lifelog_data.items(): \n",
    "    globals()[f\"{key}_df\"] = df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbd9424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë©”íŠ¸ë¦­ìŠ¤ íŒŒì¼ ì½ê¸°\n",
    "metrics_train = pd.read_csv(base_folder + '/ch2025_metrics_train.csv')\n",
    "sample_submission = pd.read_csv(base_folder+'/ch2025_submission_sample.csv')\n",
    "\n",
    "# âœ… ê¸°ì¤€ ìŒ (subject_id, lifelog_date) \n",
    "sample_submission['lifelog_date'] = pd.to_datetime(sample_submission['lifelog_date']) \n",
    "test_keys = set(zip(sample_submission['subject_id'], sample_submission['lifelog_date'].dt.date)) \n",
    "\n",
    "# âœ… DataFrame ë³„ timestamp ì»¬ëŸ¼ ìˆ˜ë™ ì§€ì • \n",
    "dataframes = { \n",
    "    'mACStatus': (mACStatus_df, 'timestamp'), \n",
    "    'mActivity': (mActivity_df, 'timestamp'), \n",
    "    'mAmbience': (mAmbience_df, 'timestamp'), \n",
    "    'mBle': (mBle_df, 'timestamp'), \n",
    "    'mGps': (mGps_df, 'timestamp'), \n",
    "    'mLight': (mLight_df, 'timestamp'), \n",
    "    'mScreenStatus': (mScreenStatus_df, 'timestamp'), \n",
    "    'mUsageStats': (mUsageStats_df, 'timestamp'), \n",
    "    'mWifi': (mWifi_df, 'timestamp'), \n",
    "    'wHr': (wHr_df, 'timestamp'), \n",
    "    'wLight': (wLight_df, 'timestamp'), \n",
    "    'wPedo': (wPedo_df, 'timestamp'), \n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77b6fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… ë¶„ë¦¬ í•¨ìˆ˜ \n",
    "def split_test_train(df, subject_col='subject_id', timestamp_col='timestamp'): \n",
    "    df[timestamp_col] = pd.to_datetime(df[timestamp_col], errors='coerce') \n",
    "    df = df.dropna(subset=[timestamp_col]) \n",
    "    df['date_only'] = df[timestamp_col].dt.date \n",
    "    df['key'] = list(zip(df[subject_col], df['date_only'])) \n",
    "    test_df = df[df['key'].isin(test_keys)].drop(columns=['date_only', 'key']) \n",
    "    train_df = df[~df['key'].isin(test_keys)].drop(columns=['date_only', 'key']) \n",
    "    return test_df, train_df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3416230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… ê²°ê³¼ ì €ì¥ \n",
    "for name, (df, ts_col) in dataframes.items(): \n",
    "    print(f\"â³ {name} ë¶„ë¦¬ ì¤‘...\") \n",
    "    test_df, train_df = split_test_train(df.copy(), subject_col='subject_id', timestamp_col=ts_col) \n",
    "    globals()[f\"{name}_test\"] = test_df \n",
    "    globals()[f\"{name}_train\"] = train_df \n",
    "    print(f\"âœ… {name}_test â†’ {test_df.shape}, {name}_train â†’ {train_df.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f34d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mACStatus(df): \n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp']) \n",
    "    df['date'] = df['timestamp'].dt.date \n",
    "    df = df.sort_values(['subject_id', 'timestamp']) \n",
    "    results = [] \n",
    "    for (subj, date), group in df.groupby(['subject_id', 'date']): \n",
    "        status = group['m_charging'].values # 0/1 ìƒíƒœ \n",
    "        times = group['timestamp'].values # ì¶©ì „ ìƒíƒœ ë¹„ìœ¨ \n",
    "        ratio_charging = status.mean() \n",
    "        # ìƒíƒœ ì „ì´ íšŸìˆ˜ \n",
    "        transitions = (status[1:] != status[:-1]).sum() \n",
    "        # ì—°ì†ëœ 1 ìƒíƒœ ê¸¸ì´ë“¤ \n",
    "        lengths = [] \n",
    "        current_len = 0 \n",
    "        for val in status: \n",
    "            if val == 1: \n",
    "                current_len += 1 \n",
    "            elif current_len > 0: \n",
    "                lengths.append(current_len) \n",
    "                current_len = 0 \n",
    "        if current_len > 0: \n",
    "            lengths.append(current_len) \n",
    "        avg_charging_duration = np.mean(lengths) if lengths else 0 \n",
    "        max_charging_duration = np.max(lengths) if lengths else 0 \n",
    "        results.append({ \n",
    "            'subject_id': subj, \n",
    "            'date': date, \n",
    "            'charging_ratio': ratio_charging, \n",
    "            'charging_transitions': transitions, \n",
    "            'avg_charging_duration': avg_charging_duration, \n",
    "            'max_charging_duration': max_charging_duration, \n",
    "        }) \n",
    "    return pd.DataFrame(results) \n",
    "\n",
    "mACStatus_df2 = process_mACStatus(mACStatus_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c3c0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mActivity(df): \n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp']) \n",
    "    df['date'] = df['timestamp'].dt.date \n",
    "    summary = [] \n",
    "    for (subj, date), group in df.groupby(['subject_id', 'date']): \n",
    "        counts = group['m_activity'].value_counts(normalize=True) # ë¹„ìœ¨ \n",
    "        row = {'subject_id': subj, 'date': date} \n",
    "        # 0~8 ë¹„ìœ¨ ì €ì¥ \n",
    "        for i in range(9): \n",
    "            row[f'activity_{i}_ratio'] = counts.get(i, 0) \n",
    "        # ì£¼ìš” í™œë™ ì •ë³´ \n",
    "        row['dominant_activity'] = group['m_activity'].mode()[0] \n",
    "        row['num_unique_activities'] = group['m_activity'].nunique() \n",
    "        summary.append(row) \n",
    "    return pd.DataFrame(summary) \n",
    "\n",
    "mActivity_df2 = process_mActivity(mActivity_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddb753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì§€ì •ëœ 10ê°œ ë¼ë²¨ \n",
    "top_10_labels = [ \n",
    "    \"Inside, small room\", \"Speech\", \"Silence\", \"Music\", \"Narration, monologue\", \n",
    "    \"Child speech, kid speaking\", \"Conversation\", \"Speech synthesizer\", \"Shout\", \"Babbling\" \n",
    "] \n",
    "\n",
    "def process_mAmbience_top10(df): \n",
    "    df = df.copy() \n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp']) \n",
    "    df['date'] = df['timestamp'].dt.date \n",
    "    # ì´ˆê¸°í™” \n",
    "    for label in top_10_labels + ['others']: \n",
    "        df[label] = 0.0 \n",
    "    for idx, row in df.iterrows(): \n",
    "        parsed = ast.literal_eval(row['m_ambience']) if isinstance(row['m_ambience'], str) else row['m_ambience'] \n",
    "        others_prob = 0.0 \n",
    "        for label, prob in parsed: \n",
    "            prob = float(prob) \n",
    "            if label in top_10_labels: \n",
    "                df.at[idx, label] = prob \n",
    "            else: \n",
    "                others_prob += prob \n",
    "        df.at[idx, 'others'] = others_prob \n",
    "    return df.drop(columns=['m_ambience']) \n",
    "\n",
    "mAmbience_df2= process_mAmbience_top10(mAmbience_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cc98b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_mAmbience_daily(df): \n",
    "    prob_cols = [col for col in df.columns if col not in ['subject_id', 'timestamp', 'date']] \n",
    "    # í•˜ë£¨ ë‹¨ìœ„ë¡œ í‰ê· ê°’ ìš”ì•½ \n",
    "    daily_summary = df.groupby(['subject_id', 'date'])[prob_cols].mean().reset_index() \n",
    "    return daily_summary \n",
    "\n",
    "mAmbience_df2 = summarize_mAmbience_daily(mAmbience_df2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763e541c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mBle(df): \n",
    "    df = df.copy() \n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp']) \n",
    "    df['date'] = df['timestamp'].dt.date \n",
    "    features = [] \n",
    "    for idx, row in df.iterrows(): \n",
    "        entry = ast.literal_eval(row['m_ble']) if isinstance(row['m_ble'], str) else row['m_ble'] \n",
    "        rssi_list = [] \n",
    "        class_0_cnt = 0 \n",
    "        class_other_cnt = 0 \n",
    "        for device in entry: \n",
    "            try: \n",
    "                rssi = int(device['rssi']) \n",
    "                rssi_list.append(rssi) \n",
    "                if str(device['device_class']) == '0': \n",
    "                    class_0_cnt += 1 \n",
    "                else: \n",
    "                    class_other_cnt += 1 \n",
    "            except: \n",
    "                continue # malformed record \n",
    "        feature = { \n",
    "            'subject_id': row['subject_id'], \n",
    "            'date': row['date'], \n",
    "            'device_class_0_cnt': class_0_cnt, \n",
    "            'device_class_others_cnt': class_other_cnt, \n",
    "            'device_count': len(rssi_list), \n",
    "            'rssi_mean': np.mean(rssi_list) if rssi_list else np.nan, \n",
    "            'rssi_min': np.min(rssi_list) if rssi_list else np.nan, \n",
    "            'rssi_max': np.max(rssi_list) if rssi_list else np.nan, \n",
    "        } \n",
    "        features.append(feature) \n",
    "    return pd.DataFrame(features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38ac08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_mBle_daily(df): \n",
    "    # row ë‹¨ìœ„ BLE feature ì¶”ì¶œ \n",
    "    df = process_mBle(df) \n",
    "    # í•˜ë£¨ ë‹¨ìœ„ë¡œ cnt í•©ì¹˜ê¸° \n",
    "    grouped = df.groupby(['subject_id', 'date']).agg({ \n",
    "        'device_class_0_cnt': 'sum', \n",
    "        'device_class_others_cnt': 'sum', \n",
    "        'rssi_mean': 'mean', \n",
    "        'rssi_min': 'min', \n",
    "        'rssi_max': 'max', \n",
    "    }).reset_index() \n",
    "    # ì´í•© êµ¬í•´ì„œ ë¹„ìœ¨ ê³„ì‚° \n",
    "    total_cnt = grouped['device_class_0_cnt'] + grouped['device_class_others_cnt'] \n",
    "    grouped['device_class_0_ratio'] = grouped['device_class_0_cnt'] / total_cnt.replace(0, np.nan) \n",
    "    grouped['device_class_others_ratio'] = grouped['device_class_others_cnt'] / total_cnt.replace(0, np.nan) \n",
    "    # í•„ìš” ì—†ëŠ” ì›ë˜ cnt ì»¬ëŸ¼ ì œê±° \n",
    "    grouped.drop(columns=['device_class_0_cnt', 'device_class_others_cnt'], inplace=True) \n",
    "    return grouped \n",
    "\n",
    "mBle_df2 = summarize_mBle_daily(mBle_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618d366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mGps(df): \n",
    "    df = df.copy() \n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp']) \n",
    "    df['date'] = df['timestamp'].dt.date \n",
    "    features = [] \n",
    "    for idx, row in df.iterrows(): \n",
    "        gps_list = ast.literal_eval(row['m_gps']) if isinstance(row['m_gps'], str) else row['m_gps'] \n",
    "        altitudes = [] \n",
    "        latitudes = [] \n",
    "        longitudes = [] \n",
    "        speeds = [] \n",
    "        for entry in gps_list: \n",
    "            try: \n",
    "                altitudes.append(float(entry['altitude'])) \n",
    "                latitudes.append(float(entry['latitude'])) \n",
    "                longitudes.append(float(entry['longitude'])) \n",
    "                speeds.append(float(entry['speed'])) \n",
    "            except: \n",
    "                continue \n",
    "        features.append({ \n",
    "            'subject_id': row['subject_id'], \n",
    "            'date': row['date'], \n",
    "            'altitude_mean': np.mean(altitudes) if altitudes else np.nan, \n",
    "            'latitude_std': np.std(latitudes) if latitudes else np.nan, \n",
    "            'longitude_std': np.std(longitudes) if longitudes else np.nan, \n",
    "            'speed_mean': np.mean(speeds) if speeds else np.nan, \n",
    "            'speed_max': np.max(speeds) if speeds else np.nan, \n",
    "            'speed_std': np.std(speeds) if speeds else np.nan, \n",
    "        }) \n",
    "    return pd.DataFrame(features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a0be39",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_Gps_df2 = process_mGps(mGps_df) \n",
    "m_Gps_df2 = m_Gps_df2.groupby(['subject_id', 'date']).agg({ \n",
    "    'altitude_mean': 'mean', \n",
    "    'latitude_std': 'mean', \n",
    "    'longitude_std': 'mean', \n",
    "    'speed_mean': 'mean', \n",
    "    'speed_max': 'max', \n",
    "    'speed_std': 'mean' \n",
    "}).reset_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8389d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mLight(df): \n",
    "    df = df.copy() \n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp']) \n",
    "    df['date'] = df['timestamp'].dt.date \n",
    "    df['hour'] = df['timestamp'].dt.hour \n",
    "    # ë°¤(22~05ì‹œ), ë‚®(06~21ì‹œ) êµ¬ë¶„ \n",
    "    df['is_night'] = df['hour'].apply(lambda h: h >= 22 or h < 6) \n",
    "    # í•˜ë£¨ ë‹¨ìœ„ ìš”ì•½ \n",
    "    daily = df.groupby(['subject_id', 'date']).agg( \n",
    "        light_mean=('m_light', 'mean'), \n",
    "        light_std=('m_light', 'std'), \n",
    "        light_max=('m_light', 'max'), \n",
    "        light_min=('m_light', 'min'), \n",
    "        light_night_mean=('m_light', lambda x: x[df.loc[x.index, 'is_night']].mean()), \n",
    "        light_day_mean=('m_light', lambda x: x[~df.loc[x.index, 'is_night']].mean()), \n",
    "        light_night_ratio=('is_night', 'mean') # ë°¤ ì‹œê°„ ì¸¡ì • ë¹„ìœ¨ \n",
    "    ).reset_index() \n",
    "    return daily \n",
    "\n",
    "mLight_df2 = process_mLight(mLight_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ad526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mScreenStatus(df): \n",
    "    df = df.copy() \n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp']) \n",
    "    df['date'] = df['timestamp'].dt.date \n",
    "    features = [] \n",
    "    for (subj, date), group in df.groupby(['subject_id', 'date']): \n",
    "        status = group['m_screen_use'].values \n",
    "        ratio_on = status.mean() \n",
    "        transitions = (status[1:] != status[:-1]).sum() \n",
    "        # ì—°ì†ëœ 1 ìƒíƒœ ê¸¸ì´ë“¤ \n",
    "        durations = [] \n",
    "        current = 0 \n",
    "        for val in status: \n",
    "            if val == 1: \n",
    "                current += 1 \n",
    "            elif current > 0: \n",
    "                durations.append(current) \n",
    "                current = 0 \n",
    "        if current > 0: \n",
    "            durations.append(current) \n",
    "        features.append({ \n",
    "            'subject_id': subj, \n",
    "            'date': date, \n",
    "            'screen_on_ratio': ratio_on, \n",
    "            'screen_on_transitions': transitions, \n",
    "            'screen_on_duration_avg': np.mean(durations) if durations else 0, \n",
    "            'screen_on_duration_max': np.max(durations) if durations else 0, \n",
    "        }) \n",
    "    return pd.DataFrame(features) \n",
    "\n",
    "mScreenStatus_df2 = process_mScreenStatus(mScreenStatus_df) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04edbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_apps = [ \n",
    "    'One UI í™ˆ', 'ì¹´ì¹´ì˜¤í†¡', 'ì‹œìŠ¤í…œ UI', 'NAVER', 'ìºì‹œì›Œí¬', \n",
    "    'ì„±ê²½ì¼ë…Q', 'YouTube', 'í†µí™”', 'ë©”ì‹œì§€', 'íƒ€ì„ìŠ¤í”„ë ˆë“œ', 'Instagram'\n",
    "] \n",
    "\n",
    "def process_mUsageStats(df): \n",
    "    df = df.copy() \n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp']) \n",
    "    df['date'] = df['timestamp'].dt.date \n",
    "    features = [] \n",
    "    for (subj, date), group in df.groupby(['subject_id', 'date']): \n",
    "        app_time = {app: 0 for app in top_apps} \n",
    "        others_time = 0 \n",
    "        for row in group['m_usage_stats']: \n",
    "            parsed = ast.literal_eval(row) if isinstance(row, str) else row \n",
    "            for entry in parsed: \n",
    "                app = entry.get('app_name') \n",
    "                time = entry.get('total_time', 0) \n",
    "                if app in top_apps: \n",
    "                    app_time[app] += int(time) \n",
    "                else: \n",
    "                    others_time += int(time) \n",
    "        feature = { \n",
    "            'subject_id': subj, \n",
    "            'date': date, \n",
    "            'others_time': others_time \n",
    "        } \n",
    "        # ê° ì•±ë³„ ì»¬ëŸ¼ ì¶”ê°€ \n",
    "        feature.update({f'{app}_time': app_time[app] for app in top_apps}) \n",
    "        features.append(feature) \n",
    "    return pd.DataFrame(features) \n",
    "\n",
    "mUsageStats_df2 = process_mUsageStats(mUsageStats_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bcd6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_mWifi(df): \n",
    "    df = df.copy() \n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp']) \n",
    "    df['date'] = df['timestamp'].dt.date \n",
    "    results = [] \n",
    "    for (subj, date), group in df.groupby(['subject_id', 'date']): \n",
    "        rssi_all = [] \n",
    "        for row in group['m_wifi']: \n",
    "            parsed = ast.literal_eval(row) if isinstance(row, str) else row \n",
    "            for ap in parsed: \n",
    "                try: \n",
    "                    rssi = int(ap['rssi']) \n",
    "                    rssi_all.append(rssi) \n",
    "                except: \n",
    "                    continue \n",
    "        results.append({ \n",
    "            'subject_id': subj, \n",
    "            'date': date, \n",
    "            'wifi_rssi_mean': np.mean(rssi_all) if rssi_all else np.nan, \n",
    "            'wifi_rssi_min': np.min(rssi_all) if rssi_all else np.nan, \n",
    "            'wifi_rssi_max': np.max(rssi_all) if rssi_all else np.nan, \n",
    "            'wifi_detected_cnt': len(rssi_all) \n",
    "        }) \n",
    "    return pd.DataFrame(results) \n",
    "\n",
    "mWifi_df2 = process_mWifi(mWifi_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83782374",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_time_block(hour): \n",
    "    if 0 <= hour < 6: \n",
    "        return 'early_morning' \n",
    "    elif 6 <= hour < 12: \n",
    "        return 'morning' \n",
    "    elif 12 <= hour < 18: \n",
    "        return 'afternoon' \n",
    "    else: \n",
    "        return 'evening' \n",
    "\n",
    "def process_wHr_by_timeblock(df): \n",
    "    df = df.copy() \n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp']) \n",
    "    df['date'] = df['timestamp'].dt.date \n",
    "    df['block'] = df['timestamp'].dt.hour.map(get_time_block) \n",
    "    results = [] \n",
    "    for (subj, date), group in df.groupby(['subject_id', 'date']): \n",
    "        block_stats = {'subject_id': subj, 'date': date} \n",
    "        for block, block_group in group.groupby('block'): \n",
    "            hr_all = [] \n",
    "            for row in block_group['heart_rate']: \n",
    "                parsed = ast.literal_eval(row) if isinstance(row, str) else row \n",
    "                hr_all.extend([int(h) for h in parsed if h is not None]) \n",
    "            if not hr_all: \n",
    "                continue \n",
    "            above_100 = [hr for hr in hr_all if hr > 100] \n",
    "            block_stats[f'hr_{block}_mean'] = np.mean(hr_all) \n",
    "            block_stats[f'hr_{block}_std'] = np.std(hr_all) \n",
    "            block_stats[f'hr_{block}_max'] = np.max(hr_all) \n",
    "            block_stats[f'hr_{block}_min'] = np.min(hr_all) \n",
    "            block_stats[f'hr_{block}_above_100_ratio'] = len(above_100) / len(hr_all) \n",
    "        results.append(block_stats) \n",
    "    return pd.DataFrame(results) \n",
    "\n",
    "wHr_df2 = process_wHr_by_timeblock(wHr_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39b5000",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_wLight_by_timeblock(df): \n",
    "    df = df.copy() \n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp']) \n",
    "    df['date'] = df['timestamp'].dt.date \n",
    "    df['block'] = df['timestamp'].dt.hour.map(get_time_block) \n",
    "    results = [] \n",
    "    for (subj, date), group in df.groupby(['subject_id', 'date']): \n",
    "        block_stats = {'subject_id': subj, 'date': date} \n",
    "        for block, block_group in group.groupby('block'): \n",
    "            lux = block_group['w_light'].dropna().values \n",
    "            if len(lux) == 0: \n",
    "                continue \n",
    "            block_stats[f'wlight_{block}_mean'] = np.mean(lux) \n",
    "            block_stats[f'wlight_{block}_std'] = np.std(lux) \n",
    "            block_stats[f'wlight_{block}_max'] = np.max(lux) \n",
    "            block_stats[f'wlight_{block}_min'] = np.min(lux) \n",
    "        results.append(block_stats) \n",
    "    return pd.DataFrame(results) \n",
    "\n",
    "wLight_df2 = process_wLight_by_timeblock(wLight_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55ce49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_wPedo(df): \n",
    "    df = df.copy() \n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp']) \n",
    "    df['date'] = df['timestamp'].dt.date \n",
    "    summary = df.groupby(['subject_id', 'date']).agg({ \n",
    "        'step': 'sum', \n",
    "        'step_frequency': 'mean', \n",
    "        'distance': 'sum', \n",
    "        'speed': ['mean', 'max'], \n",
    "        'burned_calories': 'sum' \n",
    "    }).reset_index() \n",
    "    # ì»¬ëŸ¼ ì´ë¦„ ì •ë¦¬ \n",
    "    summary.columns = ['subject_id', 'date', 'step_sum', 'step_frequency_mean', 'distance_sum', 'speed_mean', 'speed_max', 'burned_calories_sum'] \n",
    "    return summary \n",
    "\n",
    "wPedo_df2 = process_wPedo(wPedo_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c9a3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from functools import reduce \n",
    "df_list = [ \n",
    "    mACStatus_df2, \n",
    "    mActivity_df2,\n",
    "    mAmbience_df2, \n",
    "    mBle_df2, \n",
    "    m_Gps_df2, \n",
    "    mLight_df2, \n",
    "    mScreenStatus_df2, \n",
    "    mUsageStats_df2, \n",
    "    mWifi_df2, \n",
    "    wHr_df2, \n",
    "    wLight_df2, \n",
    "    wPedo_df2 \n",
    "] \n",
    "\n",
    "merged_df = reduce(lambda left, right: pd.merge(left, right, on=['subject_id', 'date'], how='outer'), df_list) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd23694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ì¡´ merged_df ìƒì„± í›„ ë°”ë¡œ ì¶”ê°€\n",
    "def add_personal_features(df):\n",
    "    \"\"\"ê°œì¸ë³„ íŒ¨í„´ì„ ë°˜ì˜í•œ íŠ¹ì„± ì¶”ê°€\"\"\"\n",
    "    # ê°œì¸ë³„ z-score ì •ê·œí™”\n",
    "    personal_cols = ['step_sum', 'burned_calories_sum', 'screen_on_ratio', \n",
    "                    'charging_ratio', 'light_mean', 'hr_morning_mean', \n",
    "                    'wlight_morning_mean', 'speed_mean']\n",
    "    \n",
    "    for col in personal_cols:\n",
    "        if col in df.columns:\n",
    "            # ê°œì¸ë³„ í‰ê· /í‘œì¤€í¸ì°¨ë¡œ ì •ê·œí™”\n",
    "            df[f'{col}_personal_zscore'] = df.groupby('subject_id')[col].transform(\n",
    "                lambda x: (x - x.mean()) / (x.std() + 1e-8)\n",
    "            )\n",
    "            \n",
    "            # ê°œì¸ë³„ ìˆœìœ„ (ë°±ë¶„ìœ„)\n",
    "            df[f'{col}_personal_rank'] = df.groupby('subject_id')[col].rank(pct=True)\n",
    "            \n",
    "            # ê°œì¸ë³„ ìµœëŒ“ê°’ ëŒ€ë¹„ ë¹„ìœ¨\n",
    "            df[f'{col}_personal_ratio'] = df.groupby('subject_id')[col].transform(\n",
    "                lambda x: x / (x.max() + 1e-8)\n",
    "            )\n",
    "    \n",
    "    return df\n",
    "\n",
    "# merged_df ì²˜ë¦¬ í›„ ë°”ë¡œ ì ìš©\n",
    "merged_df = add_personal_features(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5335404",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# metrics_trainì˜ lifelog_date â†’ datetime.date í˜•ìœ¼ë¡œ ë³€í™˜ \n",
    "metrics_train['lifelog_date'] = pd.to_datetime(metrics_train['lifelog_date']).dt.date \n",
    "\n",
    "# merged_dfì˜ dateë„ ë³€í™˜ \n",
    "merged_df['date'] = pd.to_datetime(merged_df['date']).dt.date \n",
    "\n",
    "# 1. date ê¸°ì¤€ ì •ë ¬ì„ ìœ„í•´ metrics_trainì˜ lifelog_date -> dateë¡œ ë§ì¶”ê¸° \n",
    "metrics_train_renamed = metrics_train.rename(columns={'lifelog_date': 'date'}) \n",
    "\n",
    "# 2. train_df: metrics_trainê³¼ ì¼ì¹˜í•˜ëŠ” (subject_id, date) â†’ ë¼ë²¨ í¬í•¨ \n",
    "train_df = pd.merge(metrics_train_renamed, merged_df, on=['subject_id', 'date'], how='inner') \n",
    "\n",
    "# 3. test_df: metrics_trainì— ì—†ëŠ” (subject_id, date) \n",
    "merged_keys = merged_df[['subject_id', 'date']] \n",
    "train_keys = metrics_train_renamed[['subject_id', 'date']] \n",
    "test_keys = pd.merge(merged_keys, train_keys, on=['subject_id', 'date'], how='left', indicator=True) \n",
    "test_keys = test_keys[test_keys['_merge'] == 'left_only'].drop(columns=['_merge']) \n",
    "test_df = pd.merge(test_keys, merged_df, on=['subject_id', 'date'], how='left') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c98b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# âœ… íƒ€ê²Ÿ ë¦¬ìŠ¤íŠ¸ \n",
    "targets_binary = ['Q1', 'Q2', 'Q3', 'S2', 'S3'] \n",
    "target_multiclass = 'S1' \n",
    "\n",
    "# âœ… feature ì¤€ë¹„ \n",
    "X = train_df.drop(columns=['subject_id', 'sleep_date', 'date', 'Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']) \n",
    "X.fillna(0, inplace=True) # ê²°ì¸¡ê°’ ì²˜ë¦¬ \n",
    "\n",
    "test_X = test_df.drop(columns=['subject_id', 'date']) \n",
    "test_X.fillna(0, inplace=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d497e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ì»¬ëŸ¼ ì´ë¦„ì—ì„œ íŠ¹ìˆ˜ ë¬¸ì ì œê±°/ë³€í™˜ \n",
    "def sanitize_column_names(df): \n",
    "    df.columns = ( \n",
    "        df.columns \n",
    "        .str.replace(r\"[^\\w]\", \"_\", regex=True) # íŠ¹ìˆ˜ë¬¸ì â†’ _ \n",
    "        .str.replace(r\"__+\", \"_\", regex=True) # ì—°ì†ëœ _ ì œê±° \n",
    "        .str.strip(\"_\") # ì•ë’¤ _ ì œê±° \n",
    "    ) \n",
    "    return df \n",
    "\n",
    "# ëª¨ë“  ì…ë ¥ì— ì ìš© \n",
    "X = sanitize_column_names(X) \n",
    "test_X = sanitize_column_names(test_X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f78cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë“  íŠ¹ì„±ì— ëŒ€í•´ ëª¨ë¸ë§ ì§„í–‰ \n",
    "X_selected = X.copy()\n",
    "test_X_selected = test_X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4655dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# # GridSearchë¥¼ ìœ„í•œ êµì°¨ ê²€ì¦ ì„¤ì •\n",
    "# cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# LightGBM ê¸°ë³¸ íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "lgbm_params = {\n",
    "    'n_estimators': 1000,\n",
    "    'learning_rate': 0.03,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'verbosity': -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ee74fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------- # \n",
    "# [ê·¸ë¦¬ë“œì„œì¹˜ ì ìš© X] \n",
    "# ì´ì§„ ë¶„ë¥˜\n",
    "binary_preds_selected = {}\n",
    "binary_models_selected = {}  # ëª¨ë¸ ê°ì²´ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬ (for Feature-Importance)\n",
    "\n",
    "\n",
    "for col in targets_binary:\n",
    "    print(f\">> {col} ë³€ìˆ˜ ì§„í–‰ ì¤‘..\")\n",
    "    y = train_df[col]\n",
    "    # ì´ì§„ ë¶„ë¥˜ìš© íŒŒë¼ë¯¸í„° ì¡°ì •\n",
    "    binary_params = lgbm_params.copy()\n",
    "    binary_params['objective'] = 'binary'\n",
    "    \n",
    "    model = LGBMClassifier(**binary_params)\n",
    "    model.fit(X_selected, y)\n",
    "    binary_preds_selected[col] = model.predict(test_X_selected)\n",
    "    binary_models_selected[col] = model  # ì—¬ê¸°ì— ëª¨ë¸ ì €ì¥\n",
    "\n",
    "# ë‹¤ì¤‘ ë¶„ë¥˜ (S1)\n",
    "print(\">> S1 ë³€ìˆ˜ ì§„í–‰ ì¤‘..\")\n",
    "\n",
    "y_multi = train_df['S1']\n",
    "# ë‹¤ì¤‘ ë¶„ë¥˜ìš© íŒŒë¼ë¯¸í„° ì„¤ì • (í´ë˜ìŠ¤ ìˆ˜ ì¶”ê°€)\n",
    "multiclass_params = lgbm_params.copy()\n",
    "multiclass_params['num_class'] = len(y_multi.unique())\n",
    "\n",
    "model_s1_selected = LGBMClassifier(**multiclass_params)\n",
    "model_s1_selected.fit(X_selected, y_multi)  \n",
    "multiclass_pred_selected = model_s1_selected.predict(test_X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931b67e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# ê° ëª¨ë¸ë³„ ìƒìœ„ 10ê°œ í”¼ì²˜ ì¤‘ìš”ë„ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬\n",
    "feature_importance_dict = {}\n",
    "\n",
    "# subplot ìˆ˜ ê³„ì‚°\n",
    "n_models = len(binary_models_selected)\n",
    "n_cols = 2  # í•œ ì¤„ì— ë‘ ê°œì”©\n",
    "n_rows = math.ceil(n_models / n_cols)\n",
    "\n",
    "# subplot ìƒì„± (10ê°œ í”¼ì²˜ë¥¼ í‘œì‹œí•˜ê¸° ìœ„í•´ ë†’ì´ ì¦ê°€)\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 8 * n_rows))\n",
    "axes = axes.flatten()  # 2D -> 1D ë°°ì—´ë¡œ ë³€í™˜\n",
    "\n",
    "for idx, (col_name, model) in enumerate(binary_models_selected.items()):\n",
    "    # ìƒìœ„ 10ê°œ í”¼ì²˜ ì¤‘ìš”ë„ ì¶”ì¶œ\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': X_selected.columns,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False).head(10)  # ìƒìœ„ 10ê°œ\n",
    "    \n",
    "    # ğŸ“Œ ê° ëª¨ë¸ë³„ë¡œ feature importance ì €ì¥\n",
    "    feature_importance_dict[col_name] = importance_df.copy()\n",
    "    \n",
    "    # ì‹œê°í™” (ìƒìœ„ 10ê°œ)\n",
    "    sns.barplot(\n",
    "        x='importance', y='feature', \n",
    "        data=importance_df, \n",
    "        ax=axes[idx], \n",
    "        palette='viridis'\n",
    "    )\n",
    "    axes[idx].set_title(f'{col_name} - Top 10 Feature Importance', fontsize=14, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Importance Score', fontsize=12)\n",
    "    axes[idx].set_ylabel('Features', fontsize=12)\n",
    "    \n",
    "    # yì¶• ë ˆì´ë¸” í¬ê¸° ì¡°ì • (20ê°œ í”¼ì²˜ëª…ì´ ê²¹ì¹˜ì§€ ì•Šë„ë¡)\n",
    "    axes[idx].tick_params(axis='y', labelsize=10)\n",
    "    axes[idx].tick_params(axis='x', labelsize=10)\n",
    "\n",
    "# ë‚¨ì€ ë¹ˆ subplot ì œê±°\n",
    "for j in range(idx + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ğŸ“Š ê° ëª¨ë¸ë³„ feature importance ê²°ê³¼ ì¶œë ¥\n",
    "print(\"=\"*60)\n",
    "print(\"ê° ëª¨ë¸ë³„ ìƒìœ„ 10ê°œ Feature Importance ì €ì¥ ì™„ë£Œ!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for model_name, df in feature_importance_dict.items():\n",
    "    print(f\"\\nğŸ”¹ {model_name} ëª¨ë¸:\")\n",
    "    print(f\"   - ìƒìœ„ 10ê°œ í”¼ì²˜ ì €ì¥ë¨\")\n",
    "    print(f\"   - ë³€ìˆ˜ëª…: feature_importance_dict['{model_name}']\")\n",
    "    print(f\"   - ìµœê³  ì¤‘ìš”ë„: {df.iloc[0]['importance']:.4f} ({df.iloc[0]['feature']})\")\n",
    "    print(f\"   - ìµœì € ì¤‘ìš”ë„: {df.iloc[-1]['importance']:.4f} ({df.iloc[-1]['feature']})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Œ ì‚¬ìš© ë°©ë²•:\")\n",
    "print(\"   - íŠ¹ì • ëª¨ë¸ ê²°ê³¼ í™•ì¸: feature_importance_dict['Q1']\")\n",
    "print(\"   - CSV ì €ì¥: feature_importance_dict['Q1'].to_csv('Q1_feature_importance.csv')\")\n",
    "print(\"   - ì „ì²´ ëª¨ë¸ ê²°ê³¼: feature_importance_dict.keys()\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e34c519",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ì¤‘ìš”ë„ ì¶”ì¶œ\n",
    "fi_multi = pd.DataFrame({\n",
    "    'feature': X_selected.columns,\n",
    "    'importance': model_s1_selected.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# top 20 features (ìƒìœ„ 20ê°œë¡œ ë³€ê²½)\n",
    "fi_multi_20 = pd.DataFrame({\n",
    "    'feature': X_selected.columns,\n",
    "    'importance': model_s1_selected.feature_importances_\n",
    "}).sort_values('importance', ascending=False).head(20)\n",
    "\n",
    "# ğŸ“Œ feature_importance_dictì— S1 ë‹¤ì¤‘ë¶„ë¥˜ ëª¨ë¸ ì €ì¥\n",
    "feature_importance_dict['S1'] = fi_multi_20.copy()\n",
    "\n",
    "# ì‹œê°í™” (ìƒìœ„ 20ê°œë¡œ ë³€ê²½)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.barplot(x='importance', y='feature', data=fi_multi_20, palette='viridis')\n",
    "plt.title('S1 ë‹¤ì¤‘ë¶„ë¥˜ ëª¨ë¸ - Top 20 Feature Importance', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Importance Score', fontsize=12)\n",
    "plt.ylabel('Features', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ğŸ“Š ì €ì¥ ì™„ë£Œ ë©”ì‹œì§€\n",
    "print(\"=\"*60)\n",
    "print(\"S1 ë‹¤ì¤‘ë¶„ë¥˜ ëª¨ë¸ Feature Importance ì €ì¥ ì™„ë£Œ!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ğŸ”¹ S1 ë‹¤ì¤‘ë¶„ë¥˜ ëª¨ë¸:\")\n",
    "print(f\"   - ìƒìœ„ 20ê°œ í”¼ì²˜ ì €ì¥ë¨\")\n",
    "print(f\"   - ë³€ìˆ˜ëª…: feature_importance_dict['S1']\")\n",
    "print(f\"   - ìµœê³  ì¤‘ìš”ë„: {fi_multi_20.iloc[0]['importance']:.4f} ({fi_multi_20.iloc[0]['feature']})\")\n",
    "print(f\"   - ìµœì € ì¤‘ìš”ë„: {fi_multi_20.iloc[-1]['importance']:.4f} ({fi_multi_20.iloc[-1]['feature']})\")\n",
    "\n",
    "print(\"\\nğŸ“Œ ì‚¬ìš© ë°©ë²•:\")\n",
    "print(\"   - S1 ë‹¤ì¤‘ë¶„ë¥˜ ê²°ê³¼ í™•ì¸: feature_importance_dict['S1']\")\n",
    "print(\"   - CSV ì €ì¥: feature_importance_dict['S1'].to_csv('S1_multiclass_feature_importance.csv')\")\n",
    "print(\"   - ì „ì²´ í”¼ì²˜ í™•ì¸: fi_multi (ëª¨ë“  í”¼ì²˜)\")\n",
    "print(\"   - ìƒìœ„ 20ê°œë§Œ: fi_multi_20\")\n",
    "\n",
    "# ğŸ“‹ í˜„ì¬ ì €ì¥ëœ ëª¨ë“  ëª¨ë¸ í™•ì¸\n",
    "print(f\"\\nğŸ’¾ í˜„ì¬ ì €ì¥ëœ ëª¨ë“  ëª¨ë¸:\")\n",
    "for model_name in feature_importance_dict.keys():\n",
    "    print(f\"   - {model_name}\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d1d732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping \n",
    "\n",
    "# GridSearchë¥¼ ìœ„í•œ êµì°¨ ê²€ì¦ ì„¤ì •\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# # LightGBM ê¸°ë³¸ íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "# lgbm_params = {\n",
    "#     'n_estimators': 1000,\n",
    "#     'learning_rate': 0.03,\n",
    "#     'random_state': 42,\n",
    "#     'n_jobs': -1,\n",
    "#     'verbosity': -1\n",
    "# }\n",
    "\n",
    "# ì´ì§„ ë¶„ë¥˜ ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ ê·¸ë¦¬ë“œ ì„œì¹˜ íŒŒë¼ë¯¸í„°\n",
    "binary_param_grid = {\n",
    "    'learning_rate': [0.01, 0.03, 0.1],\n",
    "    'n_estimators': [1000, 1500],\n",
    "    'num_leaves': [50, 100],\n",
    "    'max_depth': [-1, 5],\n",
    "    'min_child_samples': [10, 30],\n",
    "    # 'reg_alpha': [0, 0.01, 0.1],\n",
    "    # 'reg_lambda': [0, 0.01, 0.1],\n",
    "}\n",
    "\n",
    "# ë‹¤ì¤‘ ë¶„ë¥˜ ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ ê·¸ë¦¬ë“œ ì„œì¹˜ íŒŒë¼ë¯¸í„°\n",
    "multi_param_grid = {\n",
    "    'learning_rate': [0.01, 0.03, 0.1],\n",
    "    'n_estimators': [1000, 1500],\n",
    "    'num_leaves': [50, 100],\n",
    "    'max_depth': [-1, 5],\n",
    "    'min_child_samples': [10, 30],\n",
    "    # 'reg_alpha': [0, 0.01, 0.1],\n",
    "    # 'reg_lambda': [0, 0.01, 0.1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5fdf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ ê° ëª¨ë¸ë³„ ê²°í•©ëœ íŠ¹ì„±ìœ¼ë¡œ ì´ì§„ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ------------------\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from collections import Counter\n",
    "\n",
    "# ê° ëª¨ë¸ë³„ ì´ì§„ë¶„ë¥˜ ê²°ê³¼ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬\n",
    "binary_models_individual = {}\n",
    "binary_preds_individual = {}\n",
    "\n",
    "# S1ì„ ì œì™¸í•œ ì´ì§„ë¶„ë¥˜ ëª¨ë¸ë“¤\n",
    "binary_model_names = ['Q1', 'Q2', 'Q3', 'S2', 'S3']\n",
    "\n",
    "# ê° ëª¨ë¸ì´ í•´ë‹¹ íƒ€ê²Ÿë§Œ ì˜ˆì¸¡ (Q1 ëª¨ë¸â†’Q1 íƒ€ê²Ÿ, Q2 ëª¨ë¸â†’Q2 íƒ€ê²Ÿ)\n",
    "for model_name in binary_model_names:\n",
    "    # ëª¨ë¸ëª…ê³¼ íƒ€ê²Ÿëª… ë§¤ì¹­ (Q1â†’Q1, Q2â†’Q2, Q3â†’Q3, S2â†’S2, S3â†’S3)\n",
    "    target_col = model_name\n",
    "    \n",
    "    # í•´ë‹¹ ëª¨ë¸ì˜ ìƒìœ„ 20ê°œ ì¤‘ìš” í”¼ì²˜ ì„ íƒ\n",
    "    top_features = feature_importance_dict[model_name]['feature'].tolist()\n",
    "    \n",
    "    # ì¤‘ìš” í”¼ì²˜ë“¤ë¡œ ë°ì´í„° í•„í„°ë§\n",
    "    X_model_selected = X_selected[top_features]\n",
    "    test_X_model_selected = test_X_selected[top_features]\n",
    "\n",
    "    if target_col in targets_binary:\n",
    "        y = train_df[target_col]\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"ğŸ¯ {model_name} ëª¨ë¸ë¡œ {target_col} íƒ€ê²Ÿ ì˜ˆì¸¡\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # í•´ë‹¹ ëª¨ë¸ì˜ ê²°í•©ëœ íŠ¹ì„± ì‚¬ìš©\n",
    "        X_train_model = X_model_selected\n",
    "        X_test_model = test_X_model_selected\n",
    "\n",
    "        print(f\"   - ì‚¬ìš© íŠ¹ì„± ìˆ˜: {X_train_model.shape[1]}ê°œ\")\n",
    "        print(f\"   - í›ˆë ¨ ìƒ˜í”Œ ìˆ˜: {X_train_model.shape[0]}ê°œ\")\n",
    "        print(f\"   - íƒ€ê²Ÿ: {target_col}\")\n",
    "        \n",
    "        # ==================== SMOTE ì ìš© ì „í›„ í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸ ====================\n",
    "        print(f\"   - í´ë˜ìŠ¤ ìˆ˜: {len(y.unique())}ê°œ\")\n",
    "        print(f\"   - í´ë˜ìŠ¤ ë¶„í¬ (SMOTE ì ìš© ì „): {dict(y.value_counts().sort_index())}\")\n",
    "        \n",
    "        # k_neighbors ìë™ ì¡°ì • (ì†Œìˆ˜ í´ë˜ìŠ¤ ìƒ˜í”Œ ìˆ˜ ê³ ë ¤)\n",
    "        min_class_count = min(y.value_counts())\n",
    "        if min_class_count <= 3:\n",
    "            k_neighbors = max(1, min_class_count - 1)\n",
    "            print(f\"   âš ï¸  ì†Œìˆ˜ í´ë˜ìŠ¤ ìƒ˜í”Œì´ ì ì–´ k_neighborsë¥¼ {k_neighbors}ë¡œ ì¡°ì •\")\n",
    "        else:\n",
    "            k_neighbors = 3\n",
    "        \n",
    "        # SMOTE ì ìš© í›„ í´ë˜ìŠ¤ ë¶„í¬ ë¯¸ë¦¬ë³´ê¸°\n",
    "        smote_preview = SMOTE(random_state=42, k_neighbors=k_neighbors)\n",
    "        try:\n",
    "            X_resampled, y_resampled = smote_preview.fit_resample(X_train_model, y)\n",
    "            print(f\"   - í´ë˜ìŠ¤ ë¶„í¬ (SMOTE ì ìš© í›„): {dict(pd.Series(y_resampled).value_counts().sort_index())}\")\n",
    "            print(f\"   - ì´ ìƒ˜í”Œ ìˆ˜ ë³€í™”: {len(y)} â†’ {len(y_resampled)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   âš ï¸  SMOTE ë¯¸ë¦¬ë³´ê¸° ì‹¤íŒ¨: {str(e)}\")\n",
    "            k_neighbors = 1\n",
    "            print(f\"   - k_neighborsë¥¼ 1ë¡œ ì¬ì¡°ì •í•˜ì—¬ ì§„í–‰\")\n",
    "        # ===================================================================\n",
    "        \n",
    "        # SMOTE + LightGBM Pipeline\n",
    "        pipeline = ImbPipeline([\n",
    "            ('smote', SMOTE(random_state=42, k_neighbors=k_neighbors)),\n",
    "            ('classifier', LGBMClassifier(objective='binary', **lgbm_params))\n",
    "        ])\n",
    "        \n",
    "        # íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ (classifier__ ì ‘ë‘ì‚¬ ì¶”ê°€)\n",
    "        binary_param_grid_mod = {}\n",
    "        for key, value in binary_param_grid.items():\n",
    "            binary_param_grid_mod[f'classifier__{key}'] = value\n",
    "        \n",
    "        # ê·¸ë¦¬ë“œ ì„œì¹˜ë¡œ ìµœì  íŒŒë¼ë¯¸í„° ì°¾ê¸°\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=pipeline,\n",
    "            param_grid=binary_param_grid_mod,\n",
    "            scoring='f1_macro',  # ë˜ëŠ” 'roc_auc', 'precision', 'recall' ë“±\n",
    "            cv=cv,\n",
    "            verbose=0,  # ì¶œë ¥ ìµœì†Œí™”\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        print(f\"   - {model_name} ëª¨ë¸ ìµœì í™” ì¤‘... (SMOTE k_neighbors={k_neighbors})\")\n",
    "        grid_search.fit(X_train_model, y)\n",
    "        \n",
    "        print(f\"   âœ… ì™„ë£Œ!\")\n",
    "        print(f\"      - ìµœì  íŒŒë¼ë¯¸í„°: {grid_search.best_params_}\")\n",
    "        print(f\"      - ìµœê³  F1 ì ìˆ˜: {grid_search.best_score_:.4f}\")\n",
    "        \n",
    "        # ìµœì  ëª¨ë¸ê³¼ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥\n",
    "        best_model = grid_search.best_estimator_\n",
    "        predictions = best_model.predict(X_test_model)\n",
    "        \n",
    "        # ê²°ê³¼ ì €ì¥ (ë‹¨ìˆœí™”ëœ êµ¬ì¡°)\n",
    "        binary_models_individual[model_name] = best_model\n",
    "        binary_preds_individual[model_name] = predictions\n",
    "        \n",
    "        print(f\"      - ì˜ˆì¸¡ ì™„ë£Œ: {len(predictions)}ê°œ ìƒ˜í”Œ\")\n",
    "        print(f\"      - ì˜ˆì¸¡ í´ë˜ìŠ¤ ë¶„í¬: {dict(pd.Series(predictions).value_counts().sort_index())}\")\n",
    "    else:\n",
    "        print(f\"âš ï¸  {model_name} ëª¨ë¸ì— í•´ë‹¹í•˜ëŠ” íƒ€ê²Ÿ {target_col}ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ğŸ‰ ê° ëª¨ë¸ë³„ ì´ì§„ë¶„ë¥˜ í•™ìŠµ ì™„ë£Œ!\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# ğŸ“Š ê²°ê³¼ ìš”ì•½\n",
    "print(f\"\\nğŸ“Š í•™ìŠµ ì™„ë£Œ ìš”ì•½:\")\n",
    "for model_name in binary_model_names:\n",
    "    if model_name in binary_models_individual:\n",
    "        print(f\"   - {model_name} â†’ {model_name} íƒ€ê²Ÿ: âœ… í•™ìŠµ ì™„ë£Œ\")\n",
    "    else:\n",
    "        print(f\"   - {model_name} â†’ {model_name} íƒ€ê²Ÿ: âŒ í•™ìŠµ ì‹¤íŒ¨\")\n",
    "\n",
    "print(f\"\\nğŸ“Œ ê²°ê³¼ ì ‘ê·¼ ë°©ë²•:\")\n",
    "# print(f\"   - Q1 ëª¨ë¸: binary_models_individual['Q1']\")\n",
    "# print(f\"   - Q1 ì˜ˆì¸¡: binary_preds_individual['Q1']\")\n",
    "# print(f\"   - Q2 ëª¨ë¸: binary_models_individual['Q2']\")\n",
    "# print(f\"   - Q2 ì˜ˆì¸¡: binary_preds_individual['Q2']\")\n",
    "print(f\"   - í•™ìŠµëœ ëª¨ë¸ë“¤: {list(binary_models_individual.keys())}\")\n",
    "\n",
    "# ğŸ“ˆ ì„±ëŠ¥ ìš”ì•½\n",
    "def show_all_performance():\n",
    "    \"\"\"ëª¨ë“  ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½\"\"\"\n",
    "    print(f\"\\nğŸ“ˆ ëª¨ë“  ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for model_name in binary_model_names:\n",
    "        if model_name in binary_models_individual:\n",
    "            print(f\"   {model_name} â†’ {model_name}: í•™ìŠµ ì™„ë£Œ âœ…\")\n",
    "        else:\n",
    "            print(f\"   {model_name} â†’ {model_name}: í•™ìŠµ ì‹¤íŒ¨ âŒ\")\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "show_all_performance()\n",
    "\n",
    "# ğŸ“ ì˜ˆì¸¡ ê²°ê³¼ DataFrame ìƒì„± (ì„ íƒì‚¬í•­)\n",
    "def create_all_predictions_df():\n",
    "    \"\"\"ëª¨ë“  ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ìƒì„±\"\"\"\n",
    "    pred_dict = {}\n",
    "    for model_name in binary_model_names:\n",
    "        if model_name in binary_preds_individual:\n",
    "            pred_dict[f'{model_name}_pred'] = binary_preds_individual[model_name]\n",
    "    \n",
    "    return pd.DataFrame(pred_dict)\n",
    "\n",
    "print(f\"\\nğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ DataFrame ìƒì„±:\")\n",
    "print(f\"   - ì‚¬ìš©ë²•: create_all_predictions_df()\")\n",
    "print(f\"   - ê²°ê³¼: ê° ëª¨ë¸ë³„ ì˜ˆì¸¡ê°’ì´ ì»¬ëŸ¼ìœ¼ë¡œ ì €ì¥ëœ DataFrame\")\n",
    "print(f\"   - ì»¬ëŸ¼: Q1_pred, Q2_pred, Q3_pred, S2_pred, S3_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3171ae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ S1 ë‹¤ì¤‘ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ (ê°œë³„ íŠ¹ì„± ì‚¬ìš©) ------------------\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from collections import Counter\n",
    "\n",
    "# S1 ë‹¤ì¤‘ë¶„ë¥˜ ê²°ê³¼ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬\n",
    "multiclass_s1_individual = {}\n",
    "multiclass_s1_preds_individual = {}\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ğŸ¯ S1 ëª¨ë¸ë¡œ S1 ë‹¤ì¤‘ë¶„ë¥˜ íƒ€ê²Ÿ ì˜ˆì¸¡\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# S1 íƒ€ê²Ÿ ë°ì´í„° ì¤€ë¹„\n",
    "target_col = 'S1'\n",
    "y_multiclass = train_df[target_col]\n",
    "\n",
    "# í•´ë‹¹ ëª¨ë¸ì˜ ìƒìœ„ 20ê°œ ì¤‘ìš” í”¼ì²˜ ì„ íƒ\n",
    "top_features = feature_importance_dict[target_col]['feature'].tolist()\n",
    "\n",
    "# ì¤‘ìš” í”¼ì²˜ë“¤ë¡œ ë°ì´í„° í•„í„°ë§\n",
    "X_model_selected = X_selected[top_features]\n",
    "test_X_model_selected = test_X_selected[top_features]\n",
    "\n",
    "# S1 ëª¨ë¸ì˜ ê²°í•©ëœ íŠ¹ì„± ì‚¬ìš©\n",
    "X_train_s1 = X_model_selected\n",
    "X_test_s1 = test_X_model_selected\n",
    "\n",
    "print(f\"   - ì‚¬ìš© íŠ¹ì„± ìˆ˜: {X_train_s1.shape[1]}ê°œ\")\n",
    "print(f\"   - í›ˆë ¨ ìƒ˜í”Œ ìˆ˜: {X_train_s1.shape[0]}ê°œ\")\n",
    "print(f\"   - íƒ€ê²Ÿ: {target_col} (ë‹¤ì¤‘ë¶„ë¥˜)\")\n",
    "print(f\"   - í´ë˜ìŠ¤ ìˆ˜: {len(y_multiclass.unique())}ê°œ\")\n",
    "print(f\"   - SMOTE ì ìš© ì „ í´ë˜ìŠ¤ ë¶„í¬: {dict(y_multiclass.value_counts().sort_index())}\")\n",
    "\n",
    "# SMOTE ì ìš©\n",
    "smote = SMOTE(random_state=42, k_neighbors=3)  # k_neighborsëŠ” ìµœì†Œ í´ë˜ìŠ¤ ìƒ˜í”Œ ìˆ˜ë³´ë‹¤ ì‘ê²Œ\n",
    "X_train_s1_smote, y_multiclass_smote = smote.fit_resample(X_train_s1, y_multiclass)\n",
    "\n",
    "print(f\"   - SMOTE ì ìš© í›„ ìƒ˜í”Œ ìˆ˜: {X_train_s1_smote.shape[0]}ê°œ\")\n",
    "print(f\"   - SMOTE ì ìš© í›„ í´ë˜ìŠ¤ ë¶„í¬: {dict(pd.Series(y_multiclass_smote).value_counts().sort_index())}\")\n",
    "\n",
    "# ë‹¤ì¤‘ë¶„ë¥˜ìš© ëª¨ë¸ ì„¤ì •\n",
    "multiclass_model = LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    metric='multi_logloss',\n",
    "    **lgbm_params\n",
    ")\n",
    "\n",
    "# ë‹¤ì¤‘ë¶„ë¥˜ìš© íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ\n",
    "multiclass_param_grid = binary_param_grid.copy()\n",
    "\n",
    "# ê·¸ë¦¬ë“œ ì„œì¹˜ë¡œ ìµœì  íŒŒë¼ë¯¸í„° ì°¾ê¸° (SMOTE ì ìš©ëœ ë°ì´í„° ì‚¬ìš©)\n",
    "grid_search_multiclass = GridSearchCV(\n",
    "    estimator=multiclass_model,\n",
    "    param_grid=multiclass_param_grid,\n",
    "    scoring='f1_macro',\n",
    "    cv=cv,\n",
    "    verbose=0,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f\"   - S1 ë‹¤ì¤‘ë¶„ë¥˜ ëª¨ë¸ ìµœì í™” ì¤‘...\")\n",
    "grid_search_multiclass.fit(X_train_s1_smote, y_multiclass_smote)  # SMOTE ë°ì´í„° ì‚¬ìš©\n",
    "\n",
    "print(f\"   âœ… ì™„ë£Œ!\")\n",
    "print(f\"      - ìµœì  íŒŒë¼ë¯¸í„°: {grid_search_multiclass.best_params_}\")\n",
    "print(f\"      - ìµœê³  F1-Macro ì ìˆ˜: {grid_search_multiclass.best_score_:.4f}\")\n",
    "\n",
    "# ìµœì  ëª¨ë¸ê³¼ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥\n",
    "best_multiclass_model = grid_search_multiclass.best_estimator_\n",
    "multiclass_predictions = best_multiclass_model.predict(X_test_s1)\n",
    "multiclass_probabilities = best_multiclass_model.predict_proba(X_test_s1)\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "multiclass_s1_individual['model'] = best_multiclass_model\n",
    "multiclass_s1_individual['predictions'] = multiclass_predictions\n",
    "multiclass_s1_individual['probabilities'] = multiclass_probabilities\n",
    "multiclass_s1_individual['classes'] = best_multiclass_model.classes_\n",
    "\n",
    "print(f\"      - ì˜ˆì¸¡ ì™„ë£Œ: {len(multiclass_predictions)}ê°œ ìƒ˜í”Œ\")\n",
    "print(f\"      - ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ ë¶„í¬: {dict(pd.Series(multiclass_predictions).value_counts().sort_index())}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ğŸ‰ S1 ë‹¤ì¤‘ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# ğŸ“Š S1 ë‹¤ì¤‘ë¶„ë¥˜ ê²°ê³¼ ìš”ì•½\n",
    "print(f\"\\nğŸ“Š S1 ë‹¤ì¤‘ë¶„ë¥˜ í•™ìŠµ ì™„ë£Œ ìš”ì•½:\")\n",
    "print(f\"   - S1 â†’ S1 ë‹¤ì¤‘ë¶„ë¥˜ íƒ€ê²Ÿ: âœ… í•™ìŠµ ì™„ë£Œ\")\n",
    "\n",
    "print(f\"\\nğŸ“Œ S1 ë‹¤ì¤‘ë¶„ë¥˜ ê²°ê³¼ ì ‘ê·¼ ë°©ë²•:\")\n",
    "print(f\"   - S1 ëª¨ë¸: multiclass_s1_individual['model']\")\n",
    "print(f\"   - S1 ì˜ˆì¸¡: multiclass_s1_individual['predictions']\")\n",
    "print(f\"   - S1 í™•ë¥ : multiclass_s1_individual['probabilities']\")\n",
    "print(f\"   - í´ë˜ìŠ¤ ì •ë³´: multiclass_s1_individual['classes']\")\n",
    "\n",
    "# ğŸ“ˆ S1 ë‹¤ì¤‘ë¶„ë¥˜ ì„±ëŠ¥ ìš”ì•½\n",
    "def show_s1_multiclass_performance():\n",
    "    \"\"\"S1 ë‹¤ì¤‘ë¶„ë¥˜ ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½\"\"\"\n",
    "    print(f\"\\nğŸ“ˆ S1 ë‹¤ì¤‘ë¶„ë¥˜ ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"   S1 â†’ S1 (ë‹¤ì¤‘ë¶„ë¥˜): í•™ìŠµ ì™„ë£Œ âœ…\")\n",
    "    print(f\"   ìµœê³  F1-Macro ì ìˆ˜: {grid_search_multiclass.best_score_:.4f}\")\n",
    "    print(f\"   í´ë˜ìŠ¤ ìˆ˜: {len(multiclass_s1_individual['classes'])}ê°œ\")\n",
    "    print(f\"   í´ë˜ìŠ¤: {list(multiclass_s1_individual['classes'])}\")\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "show_s1_multiclass_performance()\n",
    "\n",
    "# ğŸ“ S1 ë‹¤ì¤‘ë¶„ë¥˜ ì˜ˆì¸¡ ê²°ê³¼ DataFrame ìƒì„±\n",
    "def create_s1_multiclass_df():\n",
    "    \"\"\"S1 ë‹¤ì¤‘ë¶„ë¥˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ìƒì„±\"\"\"\n",
    "    result_dict = {\n",
    "        'S1_multiclass_pred': multiclass_s1_individual['predictions']\n",
    "    }\n",
    "    \n",
    "    # ê° í´ë˜ìŠ¤ë³„ í™•ë¥ ë„ ì¶”ê°€\n",
    "    probabilities = multiclass_s1_individual['probabilities']\n",
    "    classes = multiclass_s1_individual['classes']\n",
    "    \n",
    "    for i, class_name in enumerate(classes):\n",
    "        result_dict[f'S1_class_{class_name}_prob'] = probabilities[:, i]\n",
    "    \n",
    "    return pd.DataFrame(result_dict)\n",
    "\n",
    "print(f\"\\nğŸ“Š S1 ë‹¤ì¤‘ë¶„ë¥˜ ì˜ˆì¸¡ ê²°ê³¼ DataFrame ìƒì„±:\")\n",
    "print(f\"   - ì‚¬ìš©ë²•: create_s1_multiclass_df()\")\n",
    "print(f\"   - ê²°ê³¼: S1 ì˜ˆì¸¡ê°’ê³¼ ê° í´ë˜ìŠ¤ë³„ í™•ë¥ ì´ í¬í•¨ëœ DataFrame\")\n",
    "\n",
    "# ğŸ“‹ ì „ì²´ ëª¨ë¸ í†µí•© ìš”ì•½\n",
    "def show_all_models_summary():\n",
    "    \"\"\"ì´ì§„ë¶„ë¥˜ + ë‹¤ì¤‘ë¶„ë¥˜ ëª¨ë“  ëª¨ë¸ ìš”ì•½\"\"\"\n",
    "    print(f\"\\nğŸ“‹ ì „ì²´ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ ìš”ì•½:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(f\"ğŸ”¹ ì´ì§„ë¶„ë¥˜ ëª¨ë¸ë“¤:\")\n",
    "    for model_name in binary_model_names:\n",
    "        if model_name in binary_models_individual:\n",
    "            print(f\"   - {model_name} â†’ {model_name}: âœ…\")\n",
    "        else:\n",
    "            print(f\"   - {model_name} â†’ {model_name}: âŒ\")\n",
    "    \n",
    "    print(f\"\\nğŸ”¹ ë‹¤ì¤‘ë¶„ë¥˜ ëª¨ë¸:\")\n",
    "    print(f\"   - S1 â†’ S1 (ë‹¤ì¤‘ë¶„ë¥˜): âœ…\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š ì´ í•™ìŠµëœ ëª¨ë¸ ìˆ˜:\")\n",
    "    binary_count = len([m for m in binary_model_names if m in binary_models_individual])\n",
    "    multiclass_count = 1 if 'model' in multiclass_s1_individual else 0\n",
    "    total_count = binary_count + multiclass_count\n",
    "    \n",
    "    print(f\"   - ì´ì§„ë¶„ë¥˜: {binary_count}ê°œ\")\n",
    "    print(f\"   - ë‹¤ì¤‘ë¶„ë¥˜: {multiclass_count}ê°œ\")\n",
    "    print(f\"   - ì´í•©: {total_count}ê°œ\")\n",
    "\n",
    "# ì „ì²´ ìš”ì•½ ì¶œë ¥\n",
    "show_all_models_summary()\n",
    "\n",
    "# ğŸ“ í†µí•© ì˜ˆì¸¡ ê²°ê³¼ ìƒì„±\n",
    "def create_all_predictions_combined():\n",
    "    \"\"\"ì´ì§„ë¶„ë¥˜ + ë‹¤ì¤‘ë¶„ë¥˜ ëª¨ë“  ì˜ˆì¸¡ ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ìƒì„±\"\"\"\n",
    "    # ì´ì§„ë¶„ë¥˜ ê²°ê³¼\n",
    "    pred_dict = {}\n",
    "    for model_name in binary_model_names:\n",
    "        if model_name in binary_preds_individual:\n",
    "            pred_dict[f'{model_name}_binary'] = binary_preds_individual[model_name]\n",
    "    \n",
    "    # ë‹¤ì¤‘ë¶„ë¥˜ ê²°ê³¼ ì¶”ê°€\n",
    "    if 'predictions' in multiclass_s1_individual:\n",
    "        pred_dict['S1_multiclass'] = multiclass_s1_individual['predictions']\n",
    "    \n",
    "    return pd.DataFrame(pred_dict)\n",
    "\n",
    "print(f\"\\nğŸ¯ í†µí•© ì˜ˆì¸¡ ê²°ê³¼ DataFrame:\")\n",
    "print(f\"   - ì‚¬ìš©ë²•: create_all_predictions_combined()\")\n",
    "print(f\"   - í¬í•¨: ëª¨ë“  ì´ì§„ë¶„ë¥˜ + S1 ë‹¤ì¤‘ë¶„ë¥˜ ì˜ˆì¸¡ ê²°ê³¼\")\n",
    "print(f\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be857a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample ê¸°ë°˜ ì œì¶œ í¬ë§· ê°€ì ¸ì˜¤ê¸°\n",
    "submission_final = sample_submission[['subject_id', 'sleep_date', 'lifelog_date']].copy()\n",
    "\n",
    "# lifelog_date ê¸°ì¤€ìœ¼ë¡œ string â†’ date í˜•ì‹ í†µì¼\n",
    "submission_final['lifelog_date'] = pd.to_datetime(submission_final['lifelog_date']).dt.date\n",
    "\n",
    "# ID ë§Œë“¤ê¸° (submissionì—ì„œ ì˜ˆì¸¡í•œ ê²°ê³¼ì™€ ì—°ê²°í•˜ê¸° ìœ„í•´)\n",
    "submission_final['ID'] = submission_final['subject_id'] + '_' + submission_final['lifelog_date'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f142a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”„ ê°œë³„ ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ ì‚¬ìš©\n",
    "# S1 ë‹¤ì¤‘ë¶„ë¥˜ ì˜ˆì¸¡ ê²°ê³¼ ì‚¬ìš©\n",
    "s1_predictions = multiclass_s1_individual['predictions']\n",
    "assert len(submission_final) == len(s1_predictions), f\"ê¸¸ì´ ë¶ˆì¼ì¹˜: submission={len(submission_final)}, S1 predictions={len(s1_predictions)}\"\n",
    "\n",
    "# ë‹¤ì¤‘ ë¶„ë¥˜ ì˜ˆì¸¡ ë¶™ì´ê¸° (ê°œë³„ S1 ëª¨ë¸ ê²°ê³¼)\n",
    "submission_final['S1'] = s1_predictions\n",
    "\n",
    "# ì´ì§„ ë¶„ë¥˜ ê²°ê³¼ ë¶™ì´ê¸° (ê° ê°œë³„ ëª¨ë¸ ê²°ê³¼)\n",
    "for col in ['Q1', 'Q2', 'Q3', 'S2', 'S3']:\n",
    "    # ê°œë³„ ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ ì‚¬ìš©\n",
    "    individual_predictions = binary_preds_individual[col]\n",
    "    \n",
    "    # shape ì²´í¬\n",
    "    assert len(submission_final) == len(individual_predictions), f\"ê¸¸ì´ ë¶ˆì¼ì¹˜: submission={len(submission_final)}, {col} predictions={len(individual_predictions)}\"\n",
    "    \n",
    "    submission_final[col] = individual_predictions.astype(int)  # í™•ë¥  ì•„ë‹Œ class ì˜ˆì¸¡\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ac68e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½ ì¶œë ¥\n",
    "print(\"ğŸ“Š ê°œë³„ ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for col in ['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']:\n",
    "    value_counts = submission_final[col].value_counts().sort_index()\n",
    "    total = len(submission_final)\n",
    "    print(f\"ğŸ”¹ {col}:\")\n",
    "    for value, count in value_counts.items():\n",
    "        percentage = (count / total) * 100\n",
    "        print(f\"   í´ë˜ìŠ¤ {value}: {count:,}ê°œ ({percentage:.1f}%)\")\n",
    "\n",
    "# ìµœì¢… ì œì¶œ í˜•ì‹ ì •ë ¬\n",
    "submission_final = submission_final[['subject_id', 'sleep_date', 'lifelog_date', 'Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']]\n",
    "\n",
    "\n",
    "\n",
    "# ì €ì¥\n",
    "submission_final.to_csv(submission_folder + submission_file, index=False)\n",
    "\n",
    "# VSCodeì—ì„œëŠ” files.download()ê°€ ì‘ë™í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ëŒ€ì²´\n",
    "\n",
    "print(f\"âœ… ì œì¶œ íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {os.path.abspath(submission_file)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
