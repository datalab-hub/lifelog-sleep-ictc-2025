# ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•œ ê°•ê±´í•œ ë² ì´ì§€ì•ˆ ìµœì í™”
import optuna
from optuna.samplers import TPESampler
import numpy as np
import pandas as pd
from lightgbm import LGBMClassifier
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score
import warnings
warnings.filterwarnings('ignore')

# ------------------ ê°•ê±´í•œ ë² ì´ì§€ì•ˆ ìµœì í™” í•¨ìˆ˜ ------------------
def robust_optimize_lgbm(X, y, task_type='binary', n_trials=30, study_name=None):
    """
    ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•œ ê°•ê±´í•œ ë² ì´ì§€ì•ˆ ìµœì í™”
    """
    
    def objective(trial):
        # ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•œ ë³´ìˆ˜ì ì¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ë²”ìœ„
        params = {
            'objective': 'binary' if task_type == 'binary' else 'multiclass',
            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),  # ë” ë³´ìˆ˜ì 
            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),     # ë²”ìœ„ ì¶•ì†Œ
            'num_leaves': trial.suggest_int('num_leaves', 10, 100),           # ë” ë‹¨ìˆœ
            'max_depth': trial.suggest_int('max_depth', 3, 8),                # ê¹Šì´ ì œí•œ
            'min_child_samples': trial.suggest_int('min_child_samples', 10, 50), # ë†’ì€ ìµœì†Œê°’
            'subsample': trial.suggest_float('subsample', 0.7, 0.9),          # ë” ë³´ìˆ˜ì 
            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 0.9),
            'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 0.5),          # ì •ê·œí™” ê°•í™”
            'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 0.5),
            'random_state': 42,
            'n_jobs': -1,
            'verbosity': -1,
            'force_col_wise': True  # ì•ˆì •ì„± í–¥ìƒ
        }
        
        if task_type == 'multiclass':
            params['num_class'] = len(np.unique(y))
        
        # ë” ì—„ê²©í•œ êµì°¨ê²€ì¦ (5-fold)
        model = LGBMClassifier(**params)
        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
        
        scoring = 'f1' if task_type == 'binary' else 'f1_macro'
        scores = cross_val_score(model, X, y, cv=cv, scoring=scoring, n_jobs=-1)
        
        # í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¥¼ ëª¨ë‘ ê³ ë ¤ (ì•ˆì •ì„± ì¤‘ì‹œ)
        mean_score = scores.mean()
        std_score = scores.std()
        robust_score = mean_score - 0.1 * std_score  # ë³€ë™ì„± í˜ë„í‹°
        
        return robust_score
    
    sampler = TPESampler(seed=42)
    study = optuna.create_study(
        direction='maximize',
        sampler=sampler,
        study_name=study_name or f'robust_lgbm_{task_type}'
    )
    
    print(f"ğŸ” {study_name or 'LightGBM'} ê°•ê±´í•œ ë² ì´ì§€ì•ˆ ìµœì í™” ì‹œì‘ ({n_trials}íšŒ ì‹œë„)")
    
    def callback(study, trial):
        if trial.number % 5 == 0:
            print(f"   ì‹œë„ {trial.number}: í˜„ì¬ ìµœê³  ì ìˆ˜ = {study.best_value:.4f}")
    
    study.optimize(objective, n_trials=n_trials, callbacks=[callback])
    
    print(f"âœ… ìµœì í™” ì™„ë£Œ!")
    print(f"   ìµœê³  ì ìˆ˜: {study.best_value:.4f}")
    print(f"   ìµœì  íŒŒë¼ë¯¸í„°: {study.best_params}")
    
    return study.best_params, study.best_value

# ------------------ ê²€ì¦ ê°•í™” í•¨ìˆ˜ ------------------
def validate_model_performance(X_train, y_train, X_val, y_val, params, task_type='binary'):
    """
    ëª¨ë¸ ì„±ëŠ¥ì„ ë” ì—„ê²©í•˜ê²Œ ê²€ì¦
    """
    model = LGBMClassifier(**params)
    model.fit(X_train, y_train)
    
    train_pred = model.predict(X_train)
    val_pred = model.predict(X_val)
    
    if task_type == 'binary':
        train_score = f1_score(y_train, train_pred)
        val_score = f1_score(y_val, val_pred)
    else:
        train_score = f1_score(y_train, train_pred, average='macro')
        val_score = f1_score(y_val, val_pred, average='macro')
    
    overfitting = train_score - val_score
    
    print(f"   í›ˆë ¨ F1: {train_score:.4f}")
    print(f"   ê²€ì¦ F1: {val_score:.4f}")
    print(f"   ê³¼ì í•©ë„: {overfitting:.4f} {'âš ï¸' if overfitting > 0.1 else 'âœ…'}")
    
    return val_score, overfitting

# ------------------ ê°•ê±´í•œ ì´ì§„ ë¶„ë¥˜ ìµœì í™” ------------------
print("\\n===== ê°•ê±´í•œ ë² ì´ì§€ì•ˆ ìµœì í™”ë¥¼ ì´ìš©í•œ ì´ì§„ ë¶„ë¥˜ =====")

robust_binary_preds = {}
robust_binary_params = {}
robust_binary_scores = {}

for col in targets_binary:
    print(f"\\n{'='*50}")
    print(f"ğŸ“Š {col} ê°•ê±´í•œ ì´ì§„ ë¶„ë¥˜ ìµœì í™”")
    print(f"{'='*50}")
    
    y = train_df[col]
    
    # í›ˆë ¨/ê²€ì¦ ë¶„í•  (ì‹¤ì œ ì„±ëŠ¥ í™•ì¸ìš©)
    X_train, X_val, y_train, y_val = train_test_split(
        X_combined, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # ê°•ê±´í•œ ë² ì´ì§€ì•ˆ ìµœì í™”
    best_params, best_score = robust_optimize_lgbm(
        X_train, y_train,  # í›ˆë ¨ ë°ì´í„°ë§Œ ì‚¬ìš©
        task_type='binary',
        n_trials=25,  # ì¡°ê¸ˆ ì¤„ì—¬ì„œ ê³¼ìµœì í™” ë°©ì§€
        study_name=f"robust_{col}_binary"
    )
    
    # ê²€ì¦ ì„±ëŠ¥ í™•ì¸
    print(f"\\nğŸ“Š {col} ëª¨ë¸ ê²€ì¦:")
    val_score, overfitting = validate_model_performance(
        X_train, y_train, X_val, y_val, best_params, 'binary'
    )
    
    # ê³¼ì í•©ì´ ì‹¬í•œ ê²½ìš° ë” ë‹¨ìˆœí•œ íŒŒë¼ë¯¸í„°ë¡œ ì¡°ì •
    if overfitting > 0.15:
        print(f"   âš ï¸ ê³¼ì í•© ê°ì§€! ë” ë‹¨ìˆœí•œ ëª¨ë¸ë¡œ ì¡°ì •...")
        best_params.update({
            'learning_rate': max(0.01, best_params['learning_rate'] * 0.5),
            'num_leaves': min(50, best_params['num_leaves']),
            'max_depth': min(5, best_params['max_depth']),
            'reg_alpha': best_params['reg_alpha'] + 0.1,
            'reg_lambda': best_params['reg_lambda'] + 0.1
        })
        
        # ì¬ê²€ì¦
        val_score, overfitting = validate_model_performance(
            X_train, y_train, X_val, y_val, best_params, 'binary'
        )
    
    # ì „ì²´ ë°ì´í„°ë¡œ ìµœì¢… ëª¨ë¸ í›ˆë ¨
    final_model = LGBMClassifier(**best_params)
    final_model.fit(X_combined, y)
    robust_binary_preds[col] = final_model.predict(test_X_combined)
    
    robust_binary_params[col] = best_params
    robust_binary_scores[col] = val_score  # ê²€ì¦ ì ìˆ˜ ì‚¬ìš©
    
    print(f"âœ… {col} ìµœì¢… ê²€ì¦ F1: {val_score:.4f}")

# ------------------ ê°•ê±´í•œ ë‹¤ì¤‘ ë¶„ë¥˜ ìµœì í™” ------------------
print(f"\\n{'='*50}")
print(f"ğŸ“Š S1 ê°•ê±´í•œ ë‹¤ì¤‘ ë¶„ë¥˜ ìµœì í™”")
print(f"{'='*50}")

y_multi = train_df['S1']

# í›ˆë ¨/ê²€ì¦ ë¶„í• 
X_train_multi, X_val_multi, y_train_multi, y_val_multi = train_test_split(
    X_combined, y_multi, test_size=0.2, random_state=42, stratify=y_multi
)

# ê°•ê±´í•œ ë² ì´ì§€ì•ˆ ìµœì í™”
multi_best_params, multi_best_score = robust_optimize_lgbm(
    X_train_multi, y_train_multi,
    task_type='multiclass',
    n_trials=25,
    study_name="robust_S1_multiclass"
)

# ê²€ì¦ ì„±ëŠ¥ í™•ì¸
print(f"\\nğŸ“Š S1 ëª¨ë¸ ê²€ì¦:")
val_score_multi, overfitting_multi = validate_model_performance(
    X_train_multi, y_train_multi, X_val_multi, y_val_multi, 
    multi_best_params, 'multiclass'
)

# ê³¼ì í•© ì¡°ì •
if overfitting_multi > 0.15:
    print(f"   âš ï¸ ê³¼ì í•© ê°ì§€! ë” ë‹¨ìˆœí•œ ëª¨ë¸ë¡œ ì¡°ì •...")
    multi_best_params.update({
        'learning_rate': max(0.01, multi_best_params['learning_rate'] * 0.5),
        'num_leaves': min(50, multi_best_params['num_leaves']),
        'max_depth': min(5, multi_best_params['max_depth']),
        'reg_alpha': multi_best_params['reg_alpha'] + 0.1,
        'reg_lambda': multi_best_params['reg_lambda'] + 0.1
    })
    
    val_score_multi, overfitting_multi = validate_model_performance(
        X_train_multi, y_train_multi, X_val_multi, y_val_multi, 
        multi_best_params, 'multiclass'
    )

# ì „ì²´ ë°ì´í„°ë¡œ ìµœì¢… ëª¨ë¸ í›ˆë ¨
final_multi_model = LGBMClassifier(**multi_best_params)
final_multi_model.fit(X_combined, y_multi)
robust_multiclass_pred = final_multi_model.predict(test_X_combined)

print(f"âœ… S1 ìµœì¢… ê²€ì¦ F1 macro: {val_score_multi:.4f}")

# ------------------ ê²°ê³¼ ë¹„êµ ë° ì œì¶œ íŒŒì¼ ìƒì„± ------------------
print("\\n===== ê°•ê±´í•œ ìµœì í™” ê²°ê³¼ ìš”ì•½ =====")

print("\\nğŸ“Š ê°•ê±´í•œ ì´ì§„ ë¶„ë¥˜ ê²°ê³¼:")
total_robust_score = 0
for col in targets_binary:
    print(f"  {col}: ê²€ì¦ F1 = {robust_binary_scores[col]:.4f}")
    total_robust_score += robust_binary_scores[col]

avg_robust_score = total_robust_score / len(targets_binary)
print(f"  í‰ê·  ê²€ì¦ F1: {avg_robust_score:.4f}")

print(f"\\nğŸ“Š ê°•ê±´í•œ ë‹¤ì¤‘ ë¶„ë¥˜ ê²°ê³¼:")
print(f"  S1: ê²€ì¦ F1 macro = {val_score_multi:.4f}")

# ê¸°ì¡´ ê²°ê³¼ì™€ ë¹„êµ
if 'binary_best_scores' in globals():
    print(f"\\nğŸ”„ ê¸°ì¡´ vs ê°•ê±´í•œ ìµœì í™” ë¹„êµ:")
    for col in targets_binary:
        old_score = binary_best_scores.get(col, 0)
        new_score = robust_binary_scores[col]
        diff = (new_score - old_score) * 100
        print(f"  {col}: {old_score:.4f} â†’ {new_score:.4f} ({diff:+.2f}%)")

# ê°•ê±´í•œ ì œì¶œ íŒŒì¼ ìƒì„±
submission_robust = sample_submission[['subject_id', 'sleep_date', 'lifelog_date']].copy()
submission_robust['lifelog_date'] = pd.to_datetime(submission_robust['lifelog_date']).dt.date
submission_robust['ID'] = submission_robust['subject_id'] + '_' + submission_robust['lifelog_date'].astype(str)

# ê°•ê±´í•œ ì˜ˆì¸¡ê°’ ì‚¬ìš©
submission_robust['S1'] = robust_multiclass_pred
for col in ['Q1', 'Q2', 'Q3', 'S2', 'S3']:
    submission_robust[col] = robust_binary_preds[col].astype(int)

submission_robust = submission_robust[['subject_id', 'sleep_date', 'lifelog_date', 'Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']]

# íŒŒì¼ëª…ì— ROBUST í‘œì‹œ
submission_file_robust = submission_file.replace('.csv', '_ROBUST_BAYESIAN.csv')
submission_robust.to_csv(submission_folder + submission_file_robust, index=False)

print(f"\\nâœ… ê°•ê±´í•œ ë² ì´ì§€ì•ˆ ìµœì í™” ì œì¶œ íŒŒì¼ ì €ì¥: {submission_file_robust}")

# ì¶”ê°€ ë¶„ì„: íŠ¹ì„± ì¤‘ìš”ë„ í™•ì¸
print("\\n===== ëª¨ë¸ í•´ì„ì„± ë¶„ì„ =====")
for col in targets_binary[:2]:  # ì²˜ìŒ 2ê°œë§Œ
    model = LGBMClassifier(**robust_binary_params[col])
    model.fit(X_combined, train_df[col])
    
    # íŠ¹ì„± ì¤‘ìš”ë„ ìƒìœ„ 5ê°œ
    feature_names = list(range(X_combined.shape[1]))  # íŠ¹ì„± ì´ë¦„ì´ ì—†ìœ¼ë¯€ë¡œ ì¸ë±ìŠ¤ ì‚¬ìš©
    importances = model.feature_importances_
    top_indices = np.argsort(importances)[-5:][::-1]
    
    print(f"\\n{col} ìƒìœ„ íŠ¹ì„±:")
    for i, idx in enumerate(top_indices):
        print(f"  {i+1}. íŠ¹ì„± {idx}: {importances[idx]:.4f}")

print("\\nğŸ¯ ê°•ê±´í•œ ë² ì´ì§€ì•ˆ ìµœì í™” ì™„ë£Œ!")
print("ğŸ“‹ ê³¼ì í•© ë°©ì§€ ì¡°ì¹˜:")
print("  âœ… ë³´ìˆ˜ì ì¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ë²”ìœ„")
print("  âœ… 5-fold êµì°¨ê²€ì¦")
print("  âœ… ë³€ë™ì„± í˜ë„í‹° ì ìš©")
print("  âœ… í›ˆë ¨/ê²€ì¦ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§")
print("  âœ… ìë™ ê³¼ì í•© ì¡°ì •")

print(f"\\nğŸ’¡ ê¶Œì¥ì‚¬í•­:")
print(f"  - ì´ ê°•ê±´í•œ ëª¨ë¸ì´ ì‹¤ì œ í…ŒìŠ¤íŠ¸ì—ì„œ ë” ì•ˆì •ì ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤")
print(f"  - ê²€ì¦ ì ìˆ˜ê°€ ì‹¤ì œ ì„±ëŠ¥ì— ë” ê°€ê¹Œìš¸ ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤")